Docker Swarm from Scratch:

Lab-1:

What is Docker Swarm ?
Why we were using it ? 
How to create and manage Docker Swarm ?
Create service on docker swarm 
Scaling services up and down
Inspecting docker swarm

You have 100 containers
	Health check on every containers
	Ensure all containers are u on every system
	Scaling the containers up or down depending on the load
	Adding updates/changes to all containers

Orchestration:
	Managing and controlling multiple docker containers as a single service

Tools Available:
	Docker Swarm
	Kubernetes or k8s
	Apache Mesos


On Mac Local: Perfectly worked


Install VirtualBox:

# docker-machine installed by default if not install

Install docker machine if not present via link: https://docs.docker.com/machine/install-machine/#installing-machine-directly

Javeds-MacBook-Air:DevOps-Self javedalam$ docker-machine -v
docker-machine version 0.16.2, build bd45ab13
Javeds-MacBook-Air:DevOps-Self javedalam$ 

# docker version verification
Javeds-MacBook-Air:DevOps-Self javedalam$ docker -v 
Docker version 19.03.4, build 9013bf5

Javeds-MacBook-Air:DevOps-Self javedalam$ docker-machine ls
NAME   ACTIVE   DRIVER   STATE   URL   SWARM   DOCKER   ERRORS
Javeds-MacBook-Air:DevOps-Self javedalam$ 


# create a virtual box with manager1 name, error throws 

Javeds-MacBook-Air:DevOps-Self javedalam$ docker-machine create --driver virtualbox manager1
Creating CA: /Users/javedalam/.docker/machine/certs/ca.pem
Creating client certificate: /Users/javedalam/.docker/machine/certs/cert.pem
Running pre-create checks...
Error with pre-create check: "exit status 126"
Javeds-MacBook-Air:DevOps-Self javedalam$ 

# Resolution:
https://github.com/docker/machine/issues/3628


—————————————————————————————————————————————————————————————————————————

# install virtual box

Javeds-MacBook-Air:DevOps-Self javedalam$ brew cask install virtualbox;
Updating Homebrew...

Fast-forwarded master to origin/master.
Fast-forwarded master to origin/master.
==> Downloading https://homebrew.bintray.com/bottles-portable-ruby/portable-ruby-2.6.3.mavericks.bottle.tar.gz
######################################################################## 100.0%
==> Pouring portable-ruby-2.6.3.mavericks.bottle.tar.gz
==> Homebrew has enabled anonymous aggregate formulae and cask analytics.
Read the analytics documentation (and how to opt-out) here:
  https://docs.brew.sh/Analytics

==> Auto-updated Homebrew!
Updated 2 taps (homebrew/core and homebrew/services).
==> New Formulae
adios2                              dune                                libdeflate                          pyinstaller
ahoy                                dust                                libevhtp                            pylint
aliyun-cli                          dvc                                 libffcall                           pympress
allureofthestars                    dynet                               libgr                               python@3.8
alp                                 easyengine                          libgusb                             qalculate-gtk
anime-downloader                    embree                              libkeccak                           quickjs
ansible@2.8                         ensmallen                           liblouis                            rakudo
antibody                            entityx                             libnova                             rargs
anycable-go                         erlang@21                           libopenmpt                          rav1e
anyenv                              esptool                             libpulsar                           re-flex
aom                                 eureka                              libraqm                             react-native-cli
apollo-cli                          faiss                               libserdes                           redis@4.0
appium                              fastlane                            libsigc++@2                         reprepro
appstream-glib                      fastmod                             libsixel                            riff
arduino-cli                         fasttext                            libspng                             ripgrep-all
astrometry-net                      faudio                              libtensorflow@1                     ruby@2.5

flatbuffers                         liblcf                              pwntools                            zstd
flatcc                              liblinear                           pwsafe                              zsxd
flawfinder                          liblockfile                         py2cairo                            zurl
flex                                liblqr                              py3cairo
flintrock                           libltc                              pybind11
==> Renamed Formulae
ark -> velero                                   i386-elf-binutils -> x86_64-elf-binutils        resin-cli -> balena-cli
bro -> zeek                                     i386-elf-gcc -> x86_64-elf-gcc                  todolist -> ultralist
confluent-oss -> confluent-platform             jupyter -> jupyterlab                           transmission -> transmission-cli
gloo-ctl -> glooctl                             kubernetes-helm -> helm                         usbmuxd -> libusbmuxd
gnatsd -> nats-server                           php72 -> php@7.2
hh -> hstr                                      presto -> prestodb
==> Deleted Formulae
openssl ✔               ctunnel                 gtk-murrine-engine      lysp                    plan9port               srclib
aap                     curlish                 guile@2.0               mariadb@10.0            pldebugger              sshconfigfs
aiccu                   cvs2svn                 gv                      minisat                 postgres-xc             stormpath-cli
ansible@1.9             dcal                    hana                    mldonkey                pound                   supersonic
ansible@2.0             ddar                    headphones              monax                   protobuf@2.5            swig@3.04
apel                    diffuse                 hg-flow                 mongodb                 protobuf@2.6            taisei
apm-server              docker-cloud            httest                  mongodb@3.0             protobuf@3.1            terminator
apple-gcc42             dsd                     hyper                   mongodb@3.2             pyexiv2                 thc-pptp-bruter

cockroach               gost                    llvm@3.9                php@5.6                 skipfish                zim
compose2kube            gradle@2.14             llvm@4                  php@7.0                 smlnj                   zxing-cpp
cputhrottle             grib-api                llvm@5                  php@7.1                 solr@5.5
csup                    gtk-engines             logentries              pincaster               solr@6.6

==> Tapping homebrew/cask
Cloning into '/usr/local/Homebrew/Library/Taps/homebrew/homebrew-cask'...
remote: Enumerating objects: 1, done.
remote: Counting objects: 100% (1/1), done.
remote: Total 413592 (delta 0), reused 0 (delta 0), pack-reused 413591
Receiving objects: 100% (413592/413592), 188.32 MiB | 710.00 KiB/s, done.
Resolving deltas: 100% (292158/292158), done.
Tapped 1 command and 3533 casks (3,649 files, 202MB).
==> Caveats
To install and/or use virtualbox you may need to enable its kernel extension in:
  System Preferences → Security & Privacy → General
For more information refer to vendor documentation or this Apple Technical Note:
  https://developer.apple.com/library/content/technotes/tn2459/_index.html

==> Downloading https://download.virtualbox.org/virtualbox/6.1.2/VirtualBox-6.1.2-135662-OSX.dmg
######################################################################## 100.0%
==> Verifying SHA-256 checksum for Cask 'virtualbox'.
==> Installing Cask virtualbox
==> Creating Caskroom at /usr/local/Caskroom
==> We'll set permissions properly so we won't need sudo in the future.
Password:
Sorry, try again.
Password:
==> Running installer for virtualbox; your password may be necessary.
==> Package installers may write to any location; options such as --appdir are ignored.
installer: Package name is Oracle VM VirtualBox
installer: choices changes file '/var/folders/mz/53xm61dj05x40qb1p_cgfz0w0000gn/T/choices20200213-2613-12j69xi.xml' applied
installer: Upgrading at base path /
installer: The upgrade was successful.
==> Changing ownership of paths required by virtualbox; your password may be necessary
🍺  virtualbox was successfully installed!
Javeds-MacBook-Air:DevOps-Self javedalam$

—————————————————————————————————————————————————————————————————————————

# Create Docker machines (to act as nodes for Docker Swarm)   
# Create one machine as manager and others as workers

Javeds-MacBook-Air:DevOps-Self javedalam$ docker-machine create --driver virtualbox manager1
Running pre-create checks...
(manager1) Image cache directory does not exist, creating it at /Users/javedalam/.docker/machine/cache...
(manager1) No default Boot2Docker ISO found locally, downloading the latest release...
(manager1) Latest release for github.com/boot2docker/boot2docker is v19.03.5
(manager1) Downloading /Users/javedalam/.docker/machine/cache/boot2docker.iso from https://github.com/boot2docker/boot2docker/releases/download/v19.03.5/boot2docker.iso...
(manager1) 0%....10%....20%....30%....40%....50%....60%....70%....80%....90%....100%
Creating machine...
(manager1) Copying /Users/javedalam/.docker/machine/cache/boot2docker.iso to /Users/javedalam/.docker/machine/machines/manager1/boot2docker.iso...
(manager1) Creating VirtualBox VM...
(manager1) Creating SSH key...
(manager1) Starting the VM...
(manager1) Check network to re-create if needed...
(manager1) Found a new host-only adapter: "vboxnet1"
(manager1) Waiting for an IP...
Waiting for machine to be running, this may take a few minutes...
Detecting operating system of created instance...
Waiting for SSH to be available...
Detecting the provisioner...
Provisioning with boot2docker...
Copying certs to the local machine directory...
Copying certs to the remote machine...
Setting Docker configuration on the remote daemon...
Checking connection to Docker...
Docker is up and running!
To see how to connect your Docker Client to the Docker Engine running on this virtual machine, run: docker-machine env manager1
Javeds-MacBook-Air:DevOps-Self javedalam$

—————————————————————————————————————————————————————————————————————————

# manager1 env details

Javeds-MacBook-Air:DevOps-Self javedalam$ docker-machine env manager1
export DOCKER_TLS_VERIFY="1"
export DOCKER_HOST="tcp://192.168.99.100:2376"
export DOCKER_CERT_PATH="/Users/javedalam/.docker/machine/machines/manager1"
export DOCKER_MACHINE_NAME="manager1"
# Run this command to configure your shell: 
# eval $(docker-machine env manager1)
Javeds-MacBook-Air:DevOps-Self javedalam$ 

—————————————————————————————————————————————————————————————————————————

# manager1 reflects

Javeds-MacBook-Air:DevOps-Self javedalam$ docker-machine ls
NAME       ACTIVE   DRIVER       STATE     URL                         SWARM   DOCKER     ERRORS
manager1   -        virtualbox   Running   tcp://192.168.99.100:2376           v19.03.5   

—————————————————————————————————————————————————————————————————————————

# manager1 ip reflects

Javeds-MacBook-Air:DevOps-Self javedalam$ docker-machine ip manager1
192.168.99.100
Javeds-MacBook-Air:DevOps-Self javedalam$

—————————————————————————————————————————————————————————————————————————

# Create Docker machines (to act as nodes for Docker Swarm)   
# Create one machine as manager and others as worker1

Javeds-MacBook-Air:DevOps-Self javedalam$ docker-machine create --driver virtualbox worker1
Running pre-create checks...
(worker1) Unable to get the latest Boot2Docker ISO release version:  Get https://api.github.com/repos/boot2docker/boot2docker/releases/latest: dial tcp: lookup api.github.com on [::1]:53: read udp [::1]:49607->[::1]:53: read: connection refused
Creating machine...
(worker1) Unable to get the latest Boot2Docker ISO release version:  Get https://api.github.com/repos/boot2docker/boot2docker/releases/latest: dial tcp: lookup api.github.com on [::1]:53: read udp [::1]:63050->[::1]:53: read: connection refused
(worker1) Copying /Users/javedalam/.docker/machine/cache/boot2docker.iso to /Users/javedalam/.docker/machine/machines/worker1/boot2docker.iso...
(worker1) Creating VirtualBox VM...
(worker1) Creating SSH key...
(worker1) Starting the VM...
(worker1) Check network to re-create if needed...
(worker1) Waiting for an IP...
Waiting for machine to be running, this may take a few minutes...
Detecting operating system of created instance...
Waiting for SSH to be available...
Detecting the provisioner...
Provisioning with boot2docker...
Copying certs to the local machine directory...
Copying certs to the remote machine...
Setting Docker configuration on the remote daemon...
Checking connection to Docker...
Docker is up and running!
To see how to connect your Docker Client to the Docker Engine running on this virtual machine, run: docker-machine env worker1
Javeds-MacBook-Air:DevOps-Self javedalam$ 

—————————————————————————————————————————————————————————————————————————

# general commands

Javeds-MacBook-Air:DevOps-Self javedalam$ docker-machine ls
NAME       ACTIVE   DRIVER       STATE     URL                         SWARM   DOCKER     ERRORS
manager1   -        virtualbox   Running   tcp://192.168.99.100:2376           v19.03.5   
worker1    -        virtualbox   Running   tcp://192.168.99.101:2376           v19.03.5   
Javeds-MacBook-Air:DevOps-Self javedalam$


—————————————————————————————————————————————————————————————————————————

# Create Docker machines (to act as nodes for Docker Swarm)   
# Create one machine as manager and others as worker2

Javeds-MacBook-Air:DevOps-Self javedalam$ docker-machine create --driver virtualbox worker2
Running pre-create checks...
Creating machine...
(worker2) Copying /Users/javedalam/.docker/machine/cache/boot2docker.iso to /Users/javedalam/.docker/machine/machines/worker2/boot2docker.iso...
(worker2) Creating VirtualBox VM...
(worker2) Creating SSH key...
(worker2) Starting the VM...
(worker2) Check network to re-create if needed...
(worker2) Waiting for an IP...
Waiting for machine to be running, this may take a few minutes...
Detecting operating system of created instance...
Waiting for SSH to be available...
Detecting the provisioner...
Provisioning with boot2docker...
Copying certs to the local machine directory...
Copying certs to the remote machine...
Setting Docker configuration on the remote daemon...
Checking connection to Docker...
Docker is up and running!
To see how to connect your Docker Client to the Docker Engine running on this virtual machine, run: docker-machine env worker2
Javeds-MacBook-Air:DevOps-Self javedalam$ 

—————————————————————————————————————————————————————————————————————————

# list the docker machines; 1 manager and 2 workers

Javeds-MacBook-Air:DevOps-Self javedalam$ docker-machine ls
NAME       ACTIVE   DRIVER       STATE     URL                         SWARM   DOCKER     ERRORS
manager1   -        virtualbox   Running   tcp://192.168.99.100:2376           v19.03.5   
worker1    -        virtualbox   Running   tcp://192.168.99.101:2376           v19.03.5   
worker2    -        virtualbox   Running   tcp://192.168.99.102:2376           v19.03.5   
Javeds-MacBook-Air:DevOps-Self javedalam$ 

—————————————————————————————————————————————————————————————————————————

# open diff tab and connect to manager and workers independently

Javeds-MacBook-Air:DevOps-Self javedalam$ docker-machine ssh manager1
   ( '>')
  /) TC (\   Core is distributed with ABSOLUTELY NO WARRANTY.
 (/-_--_-\)           www.tinycorelinux.net

docker@manager1:~$ 

Javeds-MacBook-Air:~ javedalam$ docker-machine ssh worker1
   ( '>')
  /) TC (\   Core is distributed with ABSOLUTELY NO WARRANTY.
 (/-_--_-\)           www.tinycorelinux.net

docker@worker1:~$

Javeds-MacBook-Air:~ javedalam$ docker-machine ssh worker2
   ( '>')
  /) TC (\   Core is distributed with ABSOLUTELY NO WARRANTY.
 (/-_--_-\)           www.tinycorelinux.net

docker@worker2:~$

—————————————————————————————————————————————————————————————————————————

# fetch the ip’s of manager and workers from Mac machine

Javeds-MacBook-Air:DevOps-Self javedalam$ docker-machine ls
NAME       ACTIVE   DRIVER       STATE     URL                         SWARM   DOCKER     ERRORS
manager1   -        virtualbox   Running   tcp://192.168.99.100:2376           v19.03.5   
worker1    -        virtualbox   Running   tcp://192.168.99.101:2376           v19.03.5   
worker2    -        virtualbox   Running   tcp://192.168.99.102:2376           v19.03.5   
Javeds-MacBook-Air:DevOps-Self javedalam$ 

Javeds-MacBook-Air:DevOps-Self javedalam$ docker-machine ip manager1
192.168.99.100
Javeds-MacBook-Air:DevOps-Self javedalam$ 

Javeds-MacBook-Air:DevOps-Self javedalam$ docker-machine ip worker1
192.168.99.101
Javeds-MacBook-Air:DevOps-Self javedalam$ docker-machine ip worker2
192.168.99.102
Javeds-MacBook-Air:DevOps-Self javedalam$ 

—————————————————————————————————————————————————————————————————————————

# add manager1 machine into swarm

docker@manager1:~$ docker -v
Docker version 19.03.5, build 633a0ea838

——

docker@manager1:~$                                                                                                                                           
docker@manager1:~$ docker swarm init --advertise-addr 192.168.99.100
Swarm initialized: current node (uvushf0ucxm15f3jge95uqu01) is now a manager.

To add a worker to this swarm, run the following command:

    docker swarm join --token SWMTKN-1-4uugknse0n9llnwddju1fhw6epyvalqeq3x4cuojrkpwoopaey-23dckmoz711rb1bjdyspttbx7 192.168.99.100:2377

To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.

docker@manager1:~$ 

——

docker@manager1:~$ docker node ls
ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION
ncbiom3yd3kgzgkvqr3pbr8rn *   manager1            Ready               Active              Leader              19.03.5
docker@manager1:~$ 

——

docker@worker1:~$ docker -v
Docker version 19.03.5, build 633a0ea838
docker@worker1:~$                                                                                                                                            
docker@worker1:~$ docker node ls
Error response from daemon: This node is not a swarm manager. Use "docker swarm init" or "docker swarm join" to connect this node to swarm and try again.
docker@worker1:~$ 

——

docker@manager1:~$ docker swarm join-token worker                   
To add a worker to this swarm, run the following command:

    docker swarm join --token SWMTKN-1-4uugknse0n9llnwddju1fhw6epyvalqeq3x4cuojrkpwoopaey-23dckmoz711rb1bjdyspttbx7 192.168.99.100:2377

docker@manager1:~$

——

docker@worker1:~$ docker swarm join --token SWMTKN-1-4uugknse0n9llnwddju1fhw6epyvalqeq3x4cuojrkpwoopaey-23dckmoz711rb1bjdyspttbx7 192.168.99.100:2377
This node joined a swarm as a worker.
docker@worker1:~$ 

——

docker@manager1:~$                                                                                                                                           
docker@manager1:~$ docker node ls                                   
ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION
uvushf0ucxm15f3jge95uqu01 *   manager1            Ready               Active              Leader              19.03.5
gbv851io7rnph07fxxps923xz     worker1             Ready               Active                                  19.03.5
docker@manager1:~$ 

——

docker@worker2:~$ docker -v
Docker version 19.03.5, build 633a0ea838
docker@worker2:~$ docker swarm join --token SWMTKN-1-4uugknse0n9llnwddju1fhw6epyvalqeq3x4cuojrkpwoopaey-23dckmoz711rb1bjdyspttbx7 192.168.99.100:2377    
This node joined a swarm as a worker.
docker@worker2:~$ 

——

docker@manager1:~$                                                                                                                                           
docker@manager1:~$ docker node ls
ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION
uvushf0ucxm15f3jge95uqu01 *   manager1            Ready               Active              Leader              19.03.5
gbv851io7rnph07fxxps923xz     worker1             Ready               Active                                  19.03.5
iifw0cd69cjtv6twi8ndmiy9a     worker2             Ready               Active                                  19.03.5
docker@manager1:~$

—————————————————————————————————————————————————————————————————————————

docker@manager1:~$ docker info | grep "Swarm"                                                                                                                
 Swarm: active
docker@manager1:~$                                                                                                                                           
docker@manager1:~$ docker info | grep Manager
  Is Manager: true
  Managers: 1
  Autolock Managers: false
  Manager Addresses:
docker@manager1:~$ docker info | grep worker                                                                                                                 
docker@manager1:~$ docker info | grep Nodes                                                                                                                  
  Nodes: 3
docker@manager1:~$ 

—————————————————————————————————————————————————————————————————————————

docker@manager1:~$ docker swarm                                                                                                                              

Usage:	docker swarm COMMAND

Manage Swarm

Commands:
  ca          Display and rotate the root CA
  init        Initialize a swarm
  join        Join a swarm as a node and/or manager
  join-token  Manage join tokens
  leave       Leave the swarm
  unlock      Unlock swarm
  unlock-key  Manage the unlock key
  update      Update the swarm

Run 'docker swarm COMMAND --help' for more information on a command.
docker@manager1:~$        

—————————————————————————————————————————————————————————————————————————

# create services

# No services present initially:

docker@manager1:~$ docker service ls
ID                  NAME                MODE                REPLICAS            IMAGE               PORTS
docker@manager1:~$  


# create services:

docker@manager1:~$ docker service create --replicas 3 -p 80:80 --name webApp nginx
3ioajz46kj0vvta04tu7pv744
overall progress: 0 out of 3 tasks 
overall progress: 0 out of 3 tasks 
overall progress: 0 out of 3 tasks 
1/3: preparing [=================================>                 ] 
2/3: preparing [=================================>                 ] 
3/3: preparing [=================================>                 ] 
….



# Meanwhile check the services from new tab

docker@manager1:~$ docker service ls        
ID                  NAME                MODE                REPLICAS            IMAGE               PORTS
3ioajz46kj0v        webApp              replicated          0/3                 nginx:latest        *:80->80/tcp
docker@manager1:~$                                                                                                                                           
docker@manager1:~$ docker service ps webApp 
ID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE             ERROR                              PORTS
uxn4slv75hdx        webApp.1            nginx:latest        manager1            Running             Preparing 3 minutes ago                                      
rfndvoc2tw6b         \_ webApp.1        nginx:latest        worker1             Shutdown            Rejected 3 minutes ago    "No such image: nginx:latest@s…"   
pp6h2hofo1d2         \_ webApp.1        nginx:latest        worker1             Shutdown            Rejected 3 minutes ago    "No such image: nginx:latest@s…"   
3s6qnj8z56js         \_ webApp.1        nginx:latest        worker1             Shutdown            Rejected 3 minutes ago    "No such image: nginx:latest@s…"   
vso0kzyngtw9         \_ webApp.1        nginx:latest        worker1             Shutdown            Rejected 3 minutes ago    "No such image: nginx:latest@s…"   
uz7m4l9itvil        webApp.2            nginx:latest        worker2             Running             Preparing 3 minutes ago                                      
mtnhnzhjhxk0        webApp.3            nginx:latest        manager1            Running             Preparing 3 minutes ago                                      
docker@manager1:~$  


docker@worker1:~$ docker service ls
Error response from daemon: This node is not a swarm manager. Worker nodes can't be used to view or modify cluster state. Please run this command on a manager node or promote the current node to a manager.
docker@worker1:~$  


# try again to create services with different name and port

docker@manager1:~$ docker service create --replicas 3 -p 80:80 --name webApp nginx       
Error response from daemon: rpc error: code = InvalidArgument desc = port '80' is already in use by service 'webApp' (3ioajz46kj0vvta04tu7pv744) as an ingress port
docker@manager1:~$                                                                                                                                           

docker@manager1:~$ docker service create --replicas 3 -p 90:80 --name webApp nginx                                                                           
Error response from daemon: rpc error: code = AlreadyExists desc = name conflicts with an existing object: service webApp already exists
docker@manager1:~$                                                                                                                                           

docker@manager1:~$ docker service ls
ID                  NAME                MODE                REPLICAS            IMAGE               PORTS
3ioajz46kj0v        webApp              replicated          0/3                 nginx:latest        *:80->80/tcp
docker@manager1:~$ 

docker@manager1:~$ docker service create --replicas 3 -p 88:80 --name ng-App nginx 
5kqplkxcpa9wsom8o66h76qr4
overall progress: 0 out of 3 tasks 
1/3: preparing [=================================>                 ] 
2/3: preparing [=================================>                 ] 
3/3: preparing [=================================>                 ] 
…..

docker@manager1:~$ docker service ls        
ID                  NAME                MODE                REPLICAS            IMAGE               PORTS
5kqplkxcpa9w        ng-App              replicated          0/3                 nginx:latest        *:88->80/tcp
3ioajz46kj0v        webApp              replicated          0/3                 nginx:latest        *:80->80/tcp
docker@manager1:~$

docker@manager1:~$ docker service ps ng-App 
ID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE                  ERROR                              PORTS
wzmufigqeu50        ng-App.1            nginx:latest        manager1            Running             Preparing about a minute ago                                      
kxaps9hz9xcb        ng-App.2            nginx:latest        worker2             Running             Preparing 23 seconds ago                                          
ow4vgzfvh5t7         \_ ng-App.2        nginx:latest        worker1             Shutdown            Rejected 24 seconds ago        "No such image: nginx:latest@s…"   
lmgg4ae4u1xr         \_ ng-App.2        nginx:latest        worker1             Shutdown            Rejected 34 seconds ago        "No such image: nginx:latest@s…"   
q4946n91oc2r         \_ ng-App.2        nginx:latest        worker1             Shutdown            Rejected 45 seconds ago        "No such image: nginx:latest@s…"   
ffd8ecsigkkx         \_ ng-App.2        nginx:latest        worker1             Shutdown            Rejected 55 seconds ago        "No such image: nginx:latest@s…"   
bwqjxvoho93g        ng-App.3            nginx:latest        worker2             Running             Preparing about a minute ago                                      
docker@manager1:~$   


# Cross verify:

Javeds-MacBook-Air:DevOps-Self javedalam$ docker-machine ip manager1
192.168.99.100
Javeds-MacBook-Air:DevOps-Self javedalam$ docker-machine ip worker1
192.168.99.101
Javeds-MacBook-Air:DevOps-Self javedalam$ docker-machine ip worker2
192.168.99.102

http://192.168.99.100 | http://192.168.99.101 | http://192.168.99.102 

nginx page should reflect in all machines

—————————————————————————————————————————————————————————————————————————

# scale up 

docker@manager1:~$ docker service scale ng-App=4
ng-App scaled to 4
overall progress: 0 out of 4 tasks 
1/4: preparing [=================================>                 ] 
2/4: preparing [=================================>                 ] 
3/4: preparing [=================================>                 ] 
4/4: preparing [=================================>                 ] 
…

# check the scale up services

Javeds-MacBook-Air:~ javedalam$ docker-machine ssh manager1
   ( '>')
  /) TC (\   Core is distributed with ABSOLUTELY NO WARRANTY.
 (/-_--_-\)           www.tinycorelinux.net

docker@manager1:~$ docker node ls
ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION
uvushf0ucxm15f3jge95uqu01 *   manager1            Ready               Active              Leader              19.03.5
gbv851io7rnph07fxxps923xz     worker1             Ready               Active                                  19.03.5
iifw0cd69cjtv6twi8ndmiy9a     worker2             Ready               Active                                  19.03.5
docker@manager1:~$                                                                                                                                           

docker@manager1:~$ docker service ls
ID                  NAME                MODE                REPLICAS            IMAGE               PORTS
5kqplkxcpa9w        ng-App              replicated          0/4                 nginx:latest        *:88->80/tcp
3ioajz46kj0v        webApp              replicated          0/3                 nginx:latest        *:80->80/tcp
docker@manager1:~$                                                                                                                                           

docker@manager1:~$ docker service ps ng-App 
ID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE              ERROR                              PORTS
wzmufigqeu50        ng-App.1            nginx:latest        manager1            Running             Preparing 11 minutes ago                                      
kxaps9hz9xcb        ng-App.2            nginx:latest        worker2             Running             Preparing 10 minutes ago                                      
ow4vgzfvh5t7         \_ ng-App.2        nginx:latest        worker1             Shutdown            Rejected 10 minutes ago    "No such image: nginx:latest@s…"   
lmgg4ae4u1xr         \_ ng-App.2        nginx:latest        worker1             Shutdown            Rejected 10 minutes ago    "No such image: nginx:latest@s…"   
q4946n91oc2r         \_ ng-App.2        nginx:latest        worker1             Shutdown            Rejected 10 minutes ago    "No such image: nginx:latest@s…"   
ffd8ecsigkkx         \_ ng-App.2        nginx:latest        worker1             Shutdown            Rejected 10 minutes ago    "No such image: nginx:latest@s…"   
bwqjxvoho93g        ng-App.3            nginx:latest        worker2             Running             Preparing 11 minutes ago                                      
wo4q8v0do0tg        ng-App.4            nginx:latest        manager1            Running             Preparing 28 seconds ago                                      
45t47qmduvwr         \_ ng-App.4        nginx:latest        worker1             Shutdown            Rejected 28 seconds ago    "No such image: nginx:latest@s…"   
6g4vg5gcdete         \_ ng-App.4        nginx:latest        worker1             Shutdown            Rejected 38 seconds ago    "No such image: nginx:latest@s…"   
46m8lkx626x3         \_ ng-App.4        nginx:latest        worker1             Shutdown            Rejected 48 seconds ago    "No such image: nginx:latest@s…"   
oqxta5isoea1         \_ ng-App.4        nginx:latest        worker1             Shutdown            Rejected 59 seconds ago    "No such image: nginx:latest@s…"   
docker@manager1:~$                                                                                                                                           

—————————————————————————————————————————————————————————————————————————

# scale down

docker@manager1:~$ docker service scale ng-App=2  
ng-App scaled to 2
overall progress: 0 out of 2 tasks 
1/2: preparing [=================================>                 ] 
2/2: preparing [=================================>                 ] 
…

# try in new tab

docker@manager1:~$ docker service ls
ID                  NAME                MODE                REPLICAS            IMAGE               PORTS
5kqplkxcpa9w        ng-App              replicated          0/2                 nginx:latest        *:88->80/tcp
3ioajz46kj0v        webApp              replicated          0/3                 nginx:latest        *:80->80/tcp
docker@manager1:~$ docker service ps ng-App                                                                                                                  
ID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE              ERROR                              PORTS
wzmufigqeu50        ng-App.1            nginx:latest        manager1            Running             Preparing 20 minutes ago                                      
kxaps9hz9xcb        ng-App.2            nginx:latest        worker2             Running             Preparing 19 minutes ago                                      
ow4vgzfvh5t7         \_ ng-App.2        nginx:latest        worker1             Shutdown            Rejected 19 minutes ago    "No such image: nginx:latest@s…"   
lmgg4ae4u1xr         \_ ng-App.2        nginx:latest        worker1             Shutdown            Rejected 19 minutes ago    "No such image: nginx:latest@s…"   
q4946n91oc2r         \_ ng-App.2        nginx:latest        worker1             Shutdown            Rejected 19 minutes ago    "No such image: nginx:latest@s…"   
ffd8ecsigkkx         \_ ng-App.2        nginx:latest        worker1             Shutdown            Rejected 19 minutes ago    "No such image: nginx:latest@s…"   
docker@manager1:~$      

—————————————————————————————————————————————————————————————————————————

# Finally services created:

docker@manager1:~$ docker service create --replicas 3 -p 80:80 --name web nginx
rluo30nn594ckrgvvq8acyw16
overall progress: 3 out of 3 tasks 
1/3: running   [==================================================>] 
2/3: running   [==================================================>] 
3/3: running   [==================================================>] 
verify: Service converged 
docker@manager1:~$                                                                                                                                           

docker@manager1:~$ docker service ls
ID                  NAME                MODE                REPLICAS            IMAGE               PORTS
rluo30nn594c        web                 replicated          3/3                 nginx:latest        *:80->80/tcp
docker@manager1:~$                                                                                                                                           

docker@manager1:~$ docker service ps web 
ID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE                 ERROR                              PORTS
vg7xu7sv793p        web.1               nginx:latest        manager1            Running             Running 55 seconds ago                                           
kcphw5kowf2t         \_ web.1           nginx:latest        worker1             Shutdown            Rejected about a minute ago   "No such image: nginx:latest@s…"   
2uiezoqknisq         \_ web.1           nginx:latest        worker1             Shutdown            Rejected about a minute ago   "No such image: nginx:latest@s…"   
x1rekvvei9ou         \_ web.1           nginx:latest        worker1             Shutdown            Rejected about a minute ago   "No such image: nginx:latest@s…"   
ph5ae32bmzwg         \_ web.1           nginx:latest        worker1             Shutdown            Rejected 2 minutes ago        "No such image: nginx:latest@s…"   
in01bf4mde7z        web.2               nginx:latest        worker2             Running             Running about a minute ago                                       
zgxo4iehfzys        web.3               nginx:latest        manager1            Running             Running 55 seconds ago                                           
docker@manager1:~$    

—————————————————————————————————————————————————————————————————————————

# inspect, manager can inspect to all nodes as well as self

docker@manager1:~$ docker node inspect self            
[
    {
        "ID": "uvushf0ucxm15f3jge95uqu01",
        "Version": {
            "Index": 9
        },
        "CreatedAt": "2020-02-13T11:47:24.093502206Z",
        "UpdatedAt": "2020-02-13T11:47:24.617753328Z",
        "Spec": {
            "Labels": {},
            "Role": "manager",
            "Availability": "active"
        },
        "Description": {
            "Hostname": "manager1",
            "Platform": {
                "Architecture": "x86_64",
                "OS": "linux"
            },
            "Resources": {
                "NanoCPUs": 1000000000,
                "MemoryBytes": 1037537280
            },
            "Engine": {
                "EngineVersion": "19.03.5",
                "Labels": {
                    "provider": "virtualbox"
                },
                "Plugins": [
                    {
                        "Type": "Log",
                        "Name": "awslogs"
                    },
                    {
                        "Type": "Log",
                        "Name": "fluentd"
                    },
                    {
                        "Type": "Log",
                        "Name": "gcplogs"
                    },
                    {
                        "Type": "Log",
                        "Name": "gelf"
                    },
                    {
                        "Type": "Log",
                        "Name": "journald"
                    },
                    {
                        "Type": "Log",
                        "Name": "json-file"
                    },
                    {
                        "Type": "Log",
                        "Name": "local"
                    },
                    {
                        "Type": "Log",
                        "Name": "logentries"
                    },
                    {
                        "Type": "Log",
                        "Name": "splunk"
                    },
                    {
                        "Type": "Log",
                        "Name": "syslog"
                    },
                    {
                        "Type": "Network",
                        "Name": "bridge"
                    },
                    {
                        "Type": "Network",
                        "Name": "host"
                    },
                    {
                        "Type": "Network",
                        "Name": "ipvlan"
                    },
                    {
                        "Type": "Network",
                        "Name": "macvlan"
                    },
                    {
                        "Type": "Network",
                        "Name": "null"
                    },
                    {
                        "Type": "Network",
                        "Name": "overlay"
                    },
                    {
                        "Type": "Volume",
                        "Name": "local"
                    }
                ]
            },
            "TLSInfo": {
                "TrustRoot": "-----BEGIN CERTIFICATE-----\nMIIBajCCARCgAwIBAgIUGd1ipKtvBYaYKuyfVh6Af7ZCzAkwCgYIKoZIzj0EAwIw\nEzERMA8GA1UEAxMIc3dhcm0tY2EwHhcNMjAwMjEzMTE0MjAwWhcNNDAwMjA4MTE0\nMjAwWjATMREwDwYDVQQDEwhzd2FybS1jYTBZMBMGByqGSM49AgEGCCqGSM49AwEH\nA0IABKekffx5oaVJ1/7Prf8uC9g7BI0m09omimZqbBn42/PYHuVFNLGekYw5DR4N\nBEiX9pJmrkk7ZgB5cd1/VhaAy/OjQjBAMA4GA1UdDwEB/wQEAwIBBjAPBgNVHRMB\nAf8EBTADAQH/MB0GA1UdDgQWBBSKaeHMR8Wl8UZEHgst7nQ/9FbhHDAKBggqhkjO\nPQQDAgNIADBFAiEAnXF28bO54deOa+ShFiFAfLD3eM/e5L7UwE/nFHJ5BmoCIG9p\nzJ1RFHfecPXE7uhSykzh0GCWiWo9zHRN92Ptxs9c\n-----END CERTIFICATE-----\n",
                "CertIssuerSubject": "MBMxETAPBgNVBAMTCHN3YXJtLWNh",
                "CertIssuerPublicKey": "MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEp6R9/HmhpUnX/s+t/y4L2DsEjSbT2iaKZmpsGfjb89ge5UU0sZ6RjDkNHg0ESJf2kmauSTtmAHlx3X9WFoDL8w=="
            }
        },
        "Status": {
            "State": "ready",
            "Addr": "192.168.99.100"
        },
        "ManagerStatus": {
            "Leader": true,
            "Reachability": "reachable",
            "Addr": "192.168.99.100:2377"
        }
    }
]
docker@manager1:~$ docker node inspect self | grep Status                                                                                                    
        "Status": {
        "ManagerStatus": {
docker@manager1:~$  

docker@manager1:~$ docker node inspect self | grep State          
            "State": "ready",
docker@manager1:~$ docker node inspect worker1 | grep State                                                                                                  
            "State": "ready",
docker@manager1:~$ docker node inspect worker2 | grep State                                                                                                  
            "State": "ready",
docker@manager1:~$ 


# worker can execute inspect to manager as well as self

docker@worker1:~$ docker node inspect self 
[]
Status: Error response from daemon: This node is not a swarm manager. Worker nodes can't be used to view or modify cluster state. Please run this command on a manager node or promote the current node to a manager., Code: 1
docker@worker1:~$

—————————————————————————————————————————————————————————————————————————

# update the image version:

docker@manager1:~$ docker service update --image nginx:1.14.0 web 
web
overall progress: 0 out of 3 tasks 
1/3: preparing [=================================>                 ] 
2/3:   
3/3:   
service update paused: update paused due to failure or early termination of task 6gm97y9bk2wy19t5nf5ts3qo7
docker@manager1:~$                                                                                                                                           

docker@manager1:~$ docker service ls                              
ID                  NAME                MODE                REPLICAS            IMAGE               PORTS
rluo30nn594c        web                 replicated          2/3                 nginx:1.14.0        *:80->80/tcp
docker@manager1:~$                                                                                                                                           

docker@manager1:~$ docker service ps web                          
ID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE             ERROR                              PORTS
xq2jlkosfxqh        web.1               nginx:1.14.0        worker1             Ready               Preparing 2 seconds ago                                      
h08k8oj2jplc         \_ web.1           nginx:1.14.0        worker1             Shutdown            Rejected 2 seconds ago    "No such image: nginx:1.14.0@s…"   
6gm97y9bk2wy         \_ web.1           nginx:1.14.0        worker1             Shutdown            Rejected 12 seconds ago   "No such image: nginx:1.14.0@s…"   
vg7xu7sv793p         \_ web.1           nginx:latest        manager1            Shutdown            Shutdown 19 seconds ago                                      
kcphw5kowf2t         \_ web.1           nginx:latest        worker1             Shutdown            Rejected 3 minutes ago    "No such image: nginx:latest@s…"   
in01bf4mde7z        web.2               nginx:latest        worker2             Running             Running 3 minutes ago                                        
zgxo4iehfzys        web.3               nginx:latest        manager1            Running             Running 2 minutes ago                                        
docker@manager1:~$     

—————————————————————————————————————————————————————————————————————————

# drain the service:

docker@manager1:~$ docker service ls                                                                                                                         
ID                  NAME                MODE                REPLICAS            IMAGE               PORTS
rluo30nn594c        web                 replicated          3/3                 nginx:1.14.0        *:80->80/tcp
docker@manager1:~$                                                                                                                                           

docker@manager1:~$ docker node update --availability drain worker
worker1  worker2  

docker@manager1:~$ docker node update --availability drain worker1
worker1
docker@manager1:~$                                                                                                                                           

docker@manager1:~$ docker node ls 
ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION
uvushf0ucxm15f3jge95uqu01 *   manager1            Ready               Active              Leader              19.03.5
gbv851io7rnph07fxxps923xz     worker1             Ready               Drain                                   19.03.5
iifw0cd69cjtv6twi8ndmiy9a     worker2             Ready               Active                                  19.03.5
docker@manager1:~$

—————————————————————————————————————————————————————————————————————————

# remove the service

docker@manager1:~$ docker service rm web     
web
docker@manager1:~$                                                                                                                                           
docker@manager1:~$ docker service ls     
ID                  NAME                MODE                REPLICAS            IMAGE               PORTS
docker@manager1:~$                                                                                                                                           
docker@manager1:~$ docker node ls
ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION
uvushf0ucxm15f3jge95uqu01 *   manager1            Ready               Active              Leader              19.03.5
gbv851io7rnph07fxxps923xz     worker1             Ready               Drain                                   19.03.5
iifw0cd69cjtv6twi8ndmiy9a     worker2             Ready               Active                                  19.03.5
docker@manager1:~$ 

docker@manager1:~$ docker service ps web
no such service: web
docker@manager1:~$   

—————————————————————————————————————————————————————————————————————————

# worker left the swarm

docker@manager1:~$ docker node ls
ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION
uvushf0ucxm15f3jge95uqu01 *   manager1            Ready               Active              Leader              19.03.5
gbv851io7rnph07fxxps923xz     worker1             Ready               Drain                                   19.03.5
iifw0cd69cjtv6twi8ndmiy9a     worker2             Ready               Active                                  19.03.5
docker@manager1:~$  


docker@worker1:~$ docker swarm leave 
Node left the swarm.
docker@worker1:~$ 


docker@manager1:~$ docker node ls
ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION
uvushf0ucxm15f3jge95uqu01 *   manager1            Ready               Active              Leader              19.03.5
gbv851io7rnph07fxxps923xz     worker1             Down                Drain                                   19.03.5
iifw0cd69cjtv6twi8ndmiy9a     worker2             Ready               Active                                  19.03.5
docker@manager1:~$ 


docker@worker2:~$ docker swarm leave 
Node left the swarm.
docker@worker2:~$


docker@manager1:~$ docker node ls                                                                                                                            
ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION
uvushf0ucxm15f3jge95uqu01 *   manager1            Ready               Active              Leader              19.03.5
gbv851io7rnph07fxxps923xz     worker1             Down                Drain                                   19.03.5
iifw0cd69cjtv6twi8ndmiy9a     worker2             Down                Active                                  19.03.5
docker@manager1:~$

—————————————————————————————————————————————————————————————————————————

# stop worker1 and worker2

Javeds-MacBook-Air:DevOps-Self javedalam$ docker-machine ls
NAME       ACTIVE   DRIVER       STATE     URL                         SWARM   DOCKER     ERRORS
manager1   -        virtualbox   Running   tcp://192.168.99.100:2376           v19.03.5   
worker1    -        virtualbox   Running   tcp://192.168.99.101:2376           v19.03.5   
worker2    -        virtualbox   Running   tcp://192.168.99.102:2376           v19.03.5   
Javeds-MacBook-Air:DevOps-Self javedalam$ 

Javeds-MacBook-Air:DevOps-Self javedalam$ docker-machine stop worker1
Stopping "worker1"...
Machine "worker1" was stopped.

Javeds-MacBook-Air:DevOps-Self javedalam$ docker-machine stop worker2
Stopping "worker2"...
Machine "worker2" was stopped.
Javeds-MacBook-Air:DevOps-Self javedalam$ 


# cross verify:

docker@worker1:~$ Connection to 127.0.0.1 closed by remote host.                                                                                             
exit status 255
Javeds-MacBook-Air:~ javedalam$ 

docker@worker2:~$ Connection to 127.0.0.1 closed by remote host.                                                                                             
exit status 255
Javeds-MacBook-Air:~ javedalam$

# verify form Mac:

Javeds-MacBook-Air:~ javedalam$ docker-machine ssh worker1
Docker machine "worker1" does not exist. Use "docker-machine ls" to list machines. Use "docker-machine create" to add a new one.
Javeds-MacBook-Air:~ javedalam$ 

—————————————————————————————————————————————————————————————————————————

# remove worker1 and worker2 and lastly manager1

Javeds-MacBook-Air:DevOps-Self javedalam$ docker-machine rm worker1
About to remove worker1
WARNING: This action will delete both local reference and remote instance.
Are you sure? (y/n): y
Successfully removed worker1
Javeds-MacBook-Air:DevOps-Self javedalam$ docker-machine rm worker2
About to remove worker2
WARNING: This action will delete both local reference and remote instance.
Are you sure? (y/n): y
Successfully removed worker2
Javeds-MacBook-Air:DevOps-Self javedalam$ docker-machine rm manager1
About to remove manager1
WARNING: This action will delete both local reference and remote instance.
Are you sure? (y/n): y
Successfully removed manager1
Javeds-MacBook-Air:DevOps-Self javedalam$ 
Javeds-MacBook-Air:DevOps-Self javedalam$ docker-machine ls
NAME   ACTIVE   DRIVER   STATE   URL   SWARM   DOCKER   ERRORS
Javeds-MacBook-Air:DevOps-Self javedalam$

—————————————————————————————————————————————————————————————————————————


